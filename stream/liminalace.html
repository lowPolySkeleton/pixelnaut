<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>liminalace</title>
	<style>
		*{
		box-sizing: border-box;
		}
		html, body{
			margin: 0;
			padding: 0;
			height: 100%;
			overflow: hidden;
		}

		#canvas{
			margin-bottom: -800px;
			display: flex;
			align-items: center;
			justify-content: center;
			position: relative;
		}
		#canvas > img{
			position: absolute;
			filter: drop-shadow(0 0 20px rgba(0,0,0,.5));
		}
		.move{
			animation: move 0.2s ease-in infinite;
		}
		@keyframes move {
			0% { transform: translateY(0px)}
			50% { transform: translateY(40px) }
			100% { transform: translateY(0px)}
		}
		#shake{
			display: flex;
			align-items: center;
			justify-content: center;
			width: 100%;
			height: 100%;
			transform-origin: center bottom;
		}
		.shake{
			animation: shake 0.5s infinite;
		}
		@keyframes shake {
			0% { transform: translate(3px, 3px) rotate(0deg); }
			10% { transform: translate(-3px, -4px) rotate(-3deg); }
			20% { transform: translate(-5px, 0px) rotate(3deg); }
			30% { transform: translate(5px, 4px) rotate(0deg); }
			40% { transform: translate(3px, -3px) rotate(3deg); }
			50% { transform: translate(-3px, 4px) rotate(-3deg); }
			60% { transform: translate(-5px, 3px) rotate(0deg); }
			70% { transform: translate(5px, 3px) rotate(-3deg); }
			80% { transform: translate(-3px, -3px) rotate(3deg); }
			90% { transform: translate(3px, 5px) rotate(0deg); }
			100% { transform: translate(3px, -4px) rotate(-3deg); }
		}
	</style>
	
</head>

<body>
	<div id="shake">
		<div id="canvas">
			<img src="images/lpsFULL.png" alt="">
			<img id="jaw" src="images/lpsJAW.png" alt="">
		</div>
	</div>


	


	
	<script>
		navigator.getUserMedia = navigator.getUserMedia ||
		navigator.webkitGetUserMedia ||
		navigator.mozGetUserMedia;
		if (navigator.getUserMedia) {
		navigator.getUserMedia({
			audio: true
			},
			function(stream) {
			audioContext = new AudioContext();
			analyser = audioContext.createAnalyser();
			microphone = audioContext.createMediaStreamSource(stream);
			javascriptNode = audioContext.createScriptProcessor(2048, 1, 1);

			analyser.smoothingTimeConstant = 0.8;
			analyser.fftSize = 1024;

			microphone.connect(analyser);
			analyser.connect(javascriptNode);
			javascriptNode.connect(audioContext.destination);

			canvasContext = document.getElementById("jaw")
			shakeContext = document.getElementById("shake")

			javascriptNode.onaudioprocess = function() {

				
				var array = new Uint8Array(analyser.frequencyBinCount);
				analyser.getByteFrequencyData(array);
				var values = 0;

				var length = array.length;
				for (var i = 0; i < length; i++) {
					values += (array[i]);
				}
				
				if (values >= 9000){
					var scale = values / 100000
					console.log(values)
					canvasContext.classList.add("move");
					if(values >= 35000){
						shakeContext.classList.add("shake");
					}else{
						shakeContext.classList.remove("shake");
					}
					canvasContext.style.transform = "scale("+ (Number(scale) + 1) +")"
				}else{
					canvasContext.classList.remove("move");
					
					canvasContext.style.transform = "scale(1)"
				}


				} // end fn stream
			},
			function(err) {
			console.log("The following error occured: " + err.name)
			});
		} else {
		console.log("getUserMedia not supported");
		}

		function runSpeechRecognition() {
                // new speech recognition object
                var SpeechRecognition = SpeechRecognition;
                var recognition = new SpeechRecognition();
				canvasContext = document.getElementById("canvas")
            
                
                recognition.onspeechend = function() {
                    recognition.stop();
					runSpeechRecognition()
                }
              
               
              
                 // start recognition
                 recognition.start();
	        }


			// runSpeechRecognition()
	</script>
</body>
</html>
